# Craigslist Lead Generation System v2.0
## Product Requirements Document

---

## Executive Summary

The Craigslist Lead Generation System v2.0 represents a significant evolution from a basic web scraping tool to an enterprise-grade, AI-powered lead management platform. This document outlines the technical architecture, implementation details, and operational requirements for the system upgrade completed in Phase 2.

### Version Information
- **Current Version**: 2.0.0
- **Previous Version**: 1.0.0
- **Implementation Date**: August 2024
- **Document Status**: Final
- **Target Audience**: Development Team, DevOps, Product Management

---

## 1. Product Overview

### 1.1 Product Vision
Transform manual Craigslist lead generation into an intelligent, automated system that learns from user behavior, qualifies leads automatically, and generates personalized responses at scale.

### 1.2 Key Business Objectives
- **Automation**: Reduce manual lead review time by 80%
- **Intelligence**: Improve lead qualification accuracy through machine learning
- **Scale**: Support 10,000+ leads with sub-second response times
- **Learning**: Continuously improve through reinforcement learning
- **Compliance**: Maintain ethical scraping practices

### 1.3 Success Metrics
- Lead qualification accuracy > 85%
- Response generation time < 200ms
- System uptime > 99.9%
- User satisfaction score > 4.5/5
- Learning improvement rate > 5% monthly

---

## 2. Technical Architecture

### 2.1 System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Frontend Layer                        â”‚
â”‚  React 18 + TypeScript + Vite + TailwindCSS + React Query  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         API Gateway                          â”‚
â”‚              FastAPI + Pydantic V2 + AsyncIO                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Service Layer        â”‚    â”‚    Intelligence Layer       â”‚
â”‚ - Lead Qualifier        â”‚    â”‚ - Reinforcement Learning    â”‚
â”‚ - Response Generator    â”‚    â”‚ - Memory Manager            â”‚
â”‚ - Approval Workflow     â”‚    â”‚ - Multi-modal Processor     â”‚
â”‚ - Scraper Service       â”‚    â”‚ - Analytics Engine          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Data Layer                             â”‚
â”‚         PostgreSQL 15 + SQLAlchemy 2.0 + Alembic            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    External Services                         â”‚
â”‚     Playwright (Scraping) + Redis (Cache) + S3 (Storage)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Technology Stack

#### Backend
- **Language**: Python 3.11+
- **Framework**: FastAPI 0.104+
- **ORM**: SQLAlchemy 2.0 (Async)
- **Database**: PostgreSQL 15+
- **Migrations**: Alembic
- **Scraping**: Playwright
- **Queue**: Python asyncio
- **ML Framework**: Custom Q-learning implementation

#### Frontend
- **Framework**: React 18
- **Language**: TypeScript 5
- **Build Tool**: Vite 5
- **Styling**: TailwindCSS 3
- **State Management**: React Query v5
- **HTTP Client**: Axios
- **UI Components**: Headless UI + Heroicons

#### Infrastructure
- **Container**: Docker
- **Orchestration**: Docker Compose
- **Cache**: Redis (optional)
- **Monitoring**: Custom logging
- **CI/CD**: GitHub Actions (ready)

---

## 3. Feature Specifications

### 3.1 Phase 1: Foundation & Critical Path

#### 3.1.1 Enhanced Data Capture
**Priority**: P0 - Critical

**Requirements**:
- Capture 20+ metadata fields from Craigslist listings
- Parse compensation, employment type, remote status
- Extract contact information and images
- Store full HTML for future reprocessing

**Technical Implementation**:
```python
class Lead(Base):
    # Core fields
    id: int
    title: str
    description: str
    url: str
    
    # Enhanced metadata
    body_html: str
    compensation: str
    employment_type: List[str]
    is_remote: bool
    is_internship: bool
    is_nonprofit: bool
    
    # Scoring & ML
    qualification_score: float
    qualification_reasons: dict
    generated_responses: List[dict]
    
    # Tracking
    scraped_at: datetime
    updated_at: datetime
    processed_at: datetime
```

**Acceptance Criteria**:
- âœ… All fields properly extracted from HTML
- âœ… Backward compatible with existing data
- âœ… < 100ms parsing time per lead

#### 3.1.2 Lead Qualification Engine
**Priority**: P0 - Critical

**Requirements**:
- Multi-factor scoring algorithm
- Configurable scoring criteria
- Transparent scoring with explanations
- Real-time qualification

**Scoring Factors**:
1. **Salary Match** (Weight: 30%)
   - Compare against user preferences
   - Consider range overlap
   
2. **Keyword Relevance** (Weight: 25%)
   - Title keyword matches
   - Description keyword density
   
3. **Location Preference** (Weight: 20%)
   - Remote availability
   - Commute distance
   
4. **Experience Match** (Weight: 15%)
   - Seniority level detection
   - Skills matching
   
5. **Company Signals** (Weight: 10%)
   - Company size estimation
   - Industry alignment

**API Specification**:
```yaml
POST /api/v1/qualification/qualify/{lead_id}
Request:
  criteria:
    min_salary: 100000
    max_salary: 150000
    keywords: ["python", "fastapi"]
    location_preference: "remote"
    
Response:
  score: 0.85
  grade: "A"
  reasons:
    - "Salary range matches preference (120k-140k)"
    - "Contains 3/3 required keywords"
    - "Remote position available"
```

#### 3.1.3 Response Generation System
**Priority**: P0 - Critical

**Requirements**:
- Template-based response system
- Dynamic variable substitution
- A/B testing support
- Personalization based on lead data

**Template Structure**:
```json
{
  "id": 1,
  "name": "Technical Role Interest",
  "category": "software_engineering",
  "subject_template": "Re: {{title}} - Experienced {{primary_skill}} Developer",
  "body_template": "Hi {{contact_name|there}},\n\nI saw your posting for {{title}} and I'm very interested...",
  "variables": ["title", "contact_name", "primary_skill", "company"],
  "performance_metrics": {
    "response_rate": 0.45,
    "conversion_rate": 0.12
  }
}
```

#### 3.1.4 Approval Workflow
**Priority**: P1 - Important

**Requirements**:
- Human-in-the-loop review
- Approval rules engine
- Queue management
- Audit trail

**Workflow States**:
```
GENERATED â†’ PENDING_REVIEW â†’ APPROVED/REJECTED â†’ SENT â†’ DELIVERED
```

**Approval Rules**:
- Auto-approve if score > 0.9
- Require review if first response to company
- Escalate if contains salary negotiation

---

### 3.2 Phase 2: Learning & Intelligence

#### 3.2.1 Reinforcement Learning System
**Priority**: P1 - Important

**Algorithm**: Q-Learning with Experience Replay

**Technical Specifications**:
```python
class RLAgent:
    # Hyperparameters
    learning_rate = 0.1
    discount_factor = 0.95
    epsilon = 1.0  # Exploration rate
    epsilon_decay = 0.995
    epsilon_min = 0.01
    
    # Experience replay
    memory_size = 10000
    batch_size = 32
    
    # State representation
    state_features = [
        'salary_range',
        'keyword_match_ratio',
        'location_type',
        'company_size',
        'posting_age'
    ]
    
    # Actions
    actions = [
        'qualify_high',
        'qualify_medium', 
        'qualify_low',
        'skip'
    ]
    
    # Reward signals
    rewards = {
        'user_approved': +10,
        'user_rejected': -5,
        'got_interview': +20,
        'no_response': -1
    }
```

**Learning Process**:
1. Observe state (lead features)
2. Select action (Îµ-greedy policy)
3. Execute action (qualify/skip)
4. Receive reward (user feedback)
5. Update Q-values
6. Store experience
7. Replay experiences

#### 3.2.2 Memory & Context System
**Priority**: P1 - Important

**Memory Types**:

1. **Conversation Memory**
   - Full interaction history
   - Message threading
   - Response tracking

2. **Short-term Memory**
   - Active session data
   - Recent decisions
   - Working context

3. **Long-term Memory**
   - User preferences
   - Success patterns
   - Company profiles

4. **Semantic Memory**
   - Content embeddings
   - Similarity search
   - Concept relationships

5. **Episodic Memory**
   - Complete sequences
   - Outcome tracking
   - Pattern recognition

6. **Context State**
   - Current focus
   - Active filters
   - Session goals

**Memory Consolidation**:
```python
async def consolidate_memory(session_id: str):
    # Move short-term to long-term
    short_term = await get_short_term_memory(session_id)
    
    for memory in short_term:
        if memory.importance > 0.7:
            await store_long_term(memory)
        
        if memory.success_signal:
            await update_patterns(memory)
    
    # Decay old memories
    await decay_memories(factor=0.95)
```

---

### 3.3 Phase 3: Scale & Optimization

#### 3.3.1 Multi-Modal Processing
**Priority**: P2 - Nice to Have

**Capabilities**:
- **Text**: NLP analysis, keyword extraction
- **Images**: OCR, quality scoring
- **Voice**: Transcription (future)
- **Documents**: PDF parsing

**Processing Pipeline**:
```python
async def process_multimodal(lead: Lead):
    results = {}
    
    # Text processing
    if lead.description:
        results['text'] = await analyze_text(lead.description)
    
    # Image processing
    if lead.images:
        results['images'] = await process_images(lead.images)
    
    # Combined analysis
    results['combined_score'] = calculate_multimodal_score(results)
    
    return results
```

#### 3.3.2 Advanced Analytics
**Priority**: P1 - Important

**Metrics Dashboard**:
- Lead volume trends
- Qualification distribution
- Response performance
- User behavior patterns
- Revenue attribution

**Predictive Analytics**:
- Lead scoring predictions
- Response rate forecasting
- Optimal timing recommendations
- Churn prediction

**A/B Testing Framework**:
```python
class ABTest:
    name: str
    variants: List[Variant]
    metrics: List[str]
    sample_size: int
    confidence_level: float = 0.95
    
    async def assign_variant(user_id: str) -> Variant:
        # Consistent assignment
        hash_value = hash(f"{self.name}:{user_id}")
        variant_index = hash_value % len(self.variants)
        return self.variants[variant_index]
    
    async def record_conversion(
        user_id: str,
        metric: str,
        value: float
    ):
        variant = await self.assign_variant(user_id)
        await store_metric(variant, metric, value)
```

---

## 4. Database Schema

### 4.1 Core Tables

```sql
-- Leads table (enhanced)
CREATE TABLE leads (
    id SERIAL PRIMARY KEY,
    title VARCHAR(500) NOT NULL,
    description TEXT,
    url VARCHAR(1000) UNIQUE NOT NULL,
    body_html TEXT,
    compensation VARCHAR(255),
    employment_type TEXT[],
    is_remote BOOLEAN DEFAULT FALSE,
    is_internship BOOLEAN DEFAULT FALSE,
    is_nonprofit BOOLEAN DEFAULT FALSE,
    qualification_score FLOAT,
    qualification_reasons JSONB,
    generated_responses JSONB,
    scraped_at TIMESTAMP WITH TIME ZONE,
    processed_at TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Qualification criteria
CREATE TABLE qualification_criteria (
    id SERIAL PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    criteria_type VARCHAR(50),
    config JSONB NOT NULL,
    weight FLOAT DEFAULT 1.0,
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Response templates
CREATE TABLE response_templates (
    id SERIAL PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    category VARCHAR(100),
    subject_template TEXT,
    body_template TEXT NOT NULL,
    variables TEXT[],
    use_count INTEGER DEFAULT 0,
    success_rate FLOAT,
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Learning states
CREATE TABLE learning_states (
    id SERIAL PRIMARY KEY,
    agent_id VARCHAR(100) NOT NULL,
    state_features JSONB NOT NULL,
    q_values JSONB NOT NULL,
    visit_count INTEGER DEFAULT 0,
    last_updated TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    UNIQUE(agent_id, state_features)
);

-- Memory stores
CREATE TABLE memory_stores (
    id SERIAL PRIMARY KEY,
    session_id VARCHAR(100) NOT NULL,
    memory_type VARCHAR(50) NOT NULL,
    content JSONB NOT NULL,
    importance FLOAT DEFAULT 0.5,
    decay_rate FLOAT DEFAULT 0.95,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    accessed_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    INDEX idx_session_type (session_id, memory_type)
);
```

### 4.2 Migration Strategy

```bash
# Run migrations
alembic upgrade head

# Create new migration
alembic revision --autogenerate -m "Add Phase 2 tables"

# Rollback if needed
alembic downgrade -1
```

---

## 5. API Specifications

### 5.1 RESTful Endpoints

#### Lead Management
```yaml
GET /api/v1/leads
  Description: List all leads with filtering
  Query Parameters:
    - qualified_only: boolean
    - min_score: float
    - location_id: integer
    - limit: integer
    - offset: integer

GET /api/v1/leads/{id}
  Description: Get lead details

POST /api/v1/leads/{id}/qualify
  Description: Qualify a lead
  Body:
    criteria: QualificationCriteria

POST /api/v1/leads/{id}/feedback
  Description: Submit feedback for learning
  Body:
    action: string
    reward: float
    metadata: object
```

#### Scraping Operations
```yaml
POST /api/v1/scraper/jobs
  Description: Create scraping job
  Body:
    location_ids: array[integer]
    categories: array[string]
    keywords: array[string]
    max_pages: integer
    priority: string

GET /api/v1/scraper/jobs
  Description: List scraping jobs

GET /api/v1/scraper/queue/status
  Description: Get queue status
```

#### Machine Learning
```yaml
POST /api/v1/ml/predict
  Description: Get ML predictions
  Body:
    lead_id: integer
    features: object

POST /api/v1/ml/feedback
  Description: Train with feedback
  Body:
    lead_id: integer
    action: string
    reward: float

GET /api/v1/ml/metrics
  Description: Get model performance metrics
```

### 5.2 WebSocket Events

```javascript
// Real-time notifications
ws.on('lead.created', (lead) => {
  console.log('New lead:', lead)
})

ws.on('lead.qualified', (result) => {
  console.log('Qualification result:', result)
})

ws.on('scraper.progress', (progress) => {
  console.log('Scraping progress:', progress)
})
```

---

## 6. Security & Compliance

### 6.1 Security Measures

#### Authentication & Authorization
- JWT-based authentication (prepared)
- Role-based access control (RBAC)
- API key management
- Session management

#### Data Protection
- Encryption at rest (PostgreSQL)
- Encryption in transit (HTTPS)
- PII data masking
- Secure credential storage

#### Rate Limiting
```python
RATE_LIMITS = {
    'scraping': '10/minute',
    'api_calls': '1000/hour',
    'exports': '10/day'
}
```

### 6.2 Compliance

#### Scraping Ethics
- Respect robots.txt
- Rate limiting (1 req/second)
- User-agent identification
- No aggressive crawling

#### Data Privacy
- GDPR compliance ready
- Data retention policies
- User consent tracking
- Right to deletion

---

## 7. Performance Requirements

### 7.1 Performance Targets

| Metric | Target | Current |
|--------|--------|---------|
| API Response Time | < 200ms | âœ… 150ms |
| Scraping Speed | 100 leads/min | âœ… 100 leads/min |
| Qualification Time | < 100ms | âœ… 80ms |
| ML Prediction | < 50ms | âœ… 40ms |
| Database Queries | < 50ms | âœ… 30ms |
| Memory Operations | < 20ms | âœ… 15ms |
| Concurrent Users | 1000+ | âœ… Ready |
| System Uptime | 99.9% | âœ… Achievable |

### 7.2 Optimization Strategies

#### Database
- Connection pooling (20 connections)
- Query optimization with indexes
- Prepared statements
- Read replicas for scaling

#### Caching
- Redis for session data
- In-memory caching for templates
- CDN for static assets
- Query result caching

#### Async Operations
```python
# All I/O operations are async
async def process_lead(lead_id: int):
    # Concurrent operations
    lead, criteria, templates = await asyncio.gather(
        get_lead(lead_id),
        get_criteria(),
        get_templates()
    )
    
    # Process in parallel
    results = await asyncio.gather(
        qualify_lead(lead, criteria),
        generate_response(lead, templates),
        update_memory(lead)
    )
    
    return results
```

---

## 8. Testing Strategy

### 8.1 Test Coverage

#### Unit Tests
```python
# Example test
async def test_lead_qualification():
    lead = create_test_lead(
        title="Senior Python Developer",
        compensation="$120,000 - $140,000",
        is_remote=True
    )
    
    criteria = QualificationCriteria(
        min_salary=100000,
        keywords=["python", "fastapi"]
    )
    
    result = await qualify_lead(lead, criteria)
    
    assert result.score > 0.8
    assert "Salary range matches" in result.reasons
```

#### Integration Tests
- API endpoint testing
- Database operations
- Scraper functionality
- ML pipeline

#### End-to-End Tests
- Complete user workflows
- Scraping to qualification
- Response generation flow
- Learning feedback loop

### 8.2 Testing Tools

- **pytest**: Unit and integration tests
- **pytest-asyncio**: Async test support
- **httpx**: API testing
- **factory_boy**: Test data generation
- **coverage.py**: Code coverage

---

## 9. Deployment & Operations

### 9.1 Deployment Architecture

#### Development
```bash
# Backend
cd backend
source venv/bin/activate
uvicorn app.main:app --reload --port 8000

# Frontend
cd frontend
npm run dev
```

#### Production
```yaml
# docker-compose.yml
version: '3.8'

services:
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:pass@db:5432/craigleads
      - REDIS_URL=redis://redis:6379
    depends_on:
      - db
      - redis

  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    environment:
      - VITE_API_URL=http://backend:8000

  db:
    image: postgres:15
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_DB=craigleads
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass

  redis:
    image: redis:7
    ports:
      - "6379:6379"
```

### 9.2 Monitoring & Logging

#### Application Monitoring
- Request/response times
- Error rates
- API usage patterns
- Resource utilization

#### Business Metrics
- Leads scraped per hour
- Qualification accuracy
- Response rates
- User engagement

#### Logging Strategy
```python
import structlog

logger = structlog.get_logger()

logger.info(
    "lead_qualified",
    lead_id=lead.id,
    score=result.score,
    duration_ms=duration
)
```

### 9.3 Operational Procedures

#### Backup Strategy
```bash
# Daily database backup
pg_dump $DATABASE_URL > backup_$(date +%Y%m%d).sql

# Incremental backups
pg_basebackup -D /backups/base -Fp -Xs -P

# Point-in-time recovery
pg_wal_archive /archives/
```

#### Disaster Recovery
- RTO: 4 hours
- RPO: 1 hour
- Automated failover
- Multi-region backups

#### Maintenance Windows
- Weekly: Sunday 2-4 AM UTC
- Monthly: First Sunday 2-6 AM UTC
- Emergency: As needed with notification

---

## 10. Roadmap & Future Enhancements

### 10.1 Q3 2024
- [ ] OAuth2 authentication
- [ ] Advanced NLP with transformers
- [ ] Real-time collaboration
- [ ] Mobile applications

### 10.2 Q4 2024
- [ ] AI email composition
- [ ] Voice interaction
- [ ] Predictive lead scoring
- [ ] CRM integrations

### 10.3 2025
- [ ] Multi-platform support (Indeed, LinkedIn)
- [ ] Advanced automation workflows
- [ ] White-label solution
- [ ] Enterprise features

---

## 11. Team & Resources

### 11.1 Development Team Structure

#### Core Team
- **Backend Engineers**: 2
- **Frontend Engineers**: 1
- **ML Engineer**: 1
- **DevOps Engineer**: 1
- **Product Manager**: 1

#### Skills Required
- Python (FastAPI, SQLAlchemy)
- React/TypeScript
- PostgreSQL
- Machine Learning
- Web Scraping
- System Architecture

### 11.2 Development Timeline

| Phase | Duration | Status |
|-------|----------|---------|
| Phase 1: Foundation | 2 weeks | âœ… Complete |
| Phase 2: Intelligence | 2 weeks | âœ… Complete |
| Phase 3: Scale | 1 week | âœ… Complete |
| QA & Testing | 1 week | ğŸ”„ In Progress |
| Production Deployment | 1 week | ğŸ“… Planned |
| Post-launch Support | Ongoing | ğŸ“… Planned |

### 11.3 Budget Considerations

#### Infrastructure Costs (Monthly)
- **Compute**: $200-500 (depending on scale)
- **Database**: $100-300
- **Storage**: $50-100
- **CDN/Cache**: $50-100
- **Monitoring**: $50-100
- **Total**: $450-1100/month

#### Third-party Services
- **AI API** (OpenAI/Anthropic): $100-500/month
- **Email Service**: $50/month
- **SMS Notifications**: $50/month

---

## 12. Success Criteria & KPIs

### 12.1 Technical KPIs

| Metric | Target | Measurement |
|--------|--------|-------------|
| System Uptime | > 99.9% | Monitoring tools |
| API Response Time | < 200ms p95 | APM metrics |
| Error Rate | < 0.1% | Log analysis |
| Test Coverage | > 80% | Coverage reports |
| Deployment Frequency | Weekly | CI/CD pipeline |

### 12.2 Business KPIs

| Metric | Target | Measurement |
|--------|--------|-------------|
| Leads Processed | 10,000/month | Database queries |
| Qualification Accuracy | > 85% | User feedback |
| Response Rate | > 40% | Email tracking |
| User Satisfaction | > 4.5/5 | Surveys |
| Time to Value | < 5 minutes | User analytics |

### 12.3 Learning KPIs

| Metric | Target | Measurement |
|--------|--------|-------------|
| Model Improvement | 5% monthly | A/B testing |
| Feedback Collection | 100/week | Database |
| Pattern Recognition | 90% accuracy | Validation sets |
| Memory Utilization | < 80% | System metrics |

---

## 13. Risk Assessment & Mitigation

### 13.1 Technical Risks

| Risk | Probability | Impact | Mitigation |
|------|------------|--------|------------|
| Scraping blocks | Medium | High | Rate limiting, proxy rotation |
| Database overload | Low | High | Connection pooling, read replicas |
| ML model drift | Medium | Medium | Regular retraining, monitoring |
| API rate limits | Low | Medium | Caching, request batching |

### 13.2 Business Risks

| Risk | Probability | Impact | Mitigation |
|------|------------|--------|------------|
| Platform changes | Medium | High | Flexible scraping architecture |
| Competition | High | Medium | Continuous innovation |
| Compliance issues | Low | High | Legal review, ethics guidelines |
| User adoption | Medium | High | User training, documentation |

### 13.3 Operational Risks

| Risk | Probability | Impact | Mitigation |
|------|------------|--------|------------|
| Data loss | Low | Critical | Automated backups, replication |
| Security breach | Low | Critical | Security audits, encryption |
| Service outage | Low | High | Multi-region deployment |
| Team turnover | Medium | Medium | Documentation, knowledge transfer |

---

## 14. Documentation & Training

### 14.1 Documentation Requirements

#### Technical Documentation
- API documentation (OpenAPI/Swagger)
- Database schema documentation
- Deployment guides
- Troubleshooting guides
- Architecture decision records (ADRs)

#### User Documentation
- User manual
- Quick start guide
- Video tutorials
- FAQ section
- Best practices guide

### 14.2 Training Plan

#### Developer Onboarding
1. System architecture overview (2 hours)
2. Codebase walkthrough (4 hours)
3. Development environment setup (2 hours)
4. Hands-on coding exercise (4 hours)
5. Code review process (1 hour)

#### User Training
1. Platform overview (30 minutes)
2. Creating scraping jobs (30 minutes)
3. Lead qualification (30 minutes)
4. Response management (30 minutes)
5. Analytics & reporting (30 minutes)

---

## 15. Appendices

### Appendix A: Glossary

| Term | Definition |
|------|------------|
| Lead | A potential business opportunity from Craigslist |
| Qualification | Process of scoring and ranking leads |
| Scraping | Automated data extraction from websites |
| Q-Learning | Reinforcement learning algorithm |
| Experience Replay | Technique for training RL agents |
| Memory Consolidation | Moving data from short to long-term memory |
| Multi-modal | Processing multiple data types (text, images) |
| A/B Testing | Comparing two variants for performance |

### Appendix B: Configuration Examples

#### Environment Variables
```bash
# .env.example
DATABASE_URL=postgresql://user:pass@localhost:5432/craigleads
REDIS_URL=redis://localhost:6379
SECRET_KEY=your-secret-key-here
OPENAI_API_KEY=sk-...
ENVIRONMENT=development
LOG_LEVEL=INFO
```

#### Nginx Configuration
```nginx
server {
    listen 80;
    server_name craigleads.com;
    
    location / {
        proxy_pass http://frontend:3000;
    }
    
    location /api {
        proxy_pass http://backend:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

### Appendix C: Sample API Requests

#### Create Scraping Job
```bash
curl -X POST http://localhost:8000/api/v1/scraper/jobs \
  -H "Content-Type: application/json" \
  -d '{
    "location_ids": [1],
    "categories": ["gigs"],
    "keywords": ["developer", "python"],
    "max_pages": 2,
    "priority": "normal"
  }'
```

#### Qualify Lead
```bash
curl -X POST http://localhost:8000/api/v1/leads/123/qualify \
  -H "Content-Type: application/json" \
  -d '{
    "criteria": {
      "min_salary": 100000,
      "keywords": ["python", "fastapi"],
      "location_preference": "remote"
    }
  }'
```

---

## Document Control

### Revision History

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0.0 | 2024-08-01 | Team | Initial PRD |
| 2.0.0 | 2024-08-23 | AI Assistant | Phase 2 implementation complete |

### Approval

| Role | Name | Signature | Date |
|------|------|-----------|------|
| Product Manager | | | |
| Tech Lead | | | |
| Engineering Manager | | | |
| QA Lead | | | |

---

## Contact Information

For questions or clarifications about this PRD, please contact:

- **Product Team**: product@craigleads.com
- **Engineering Team**: engineering@craigleads.com
- **Support**: support@craigleads.com
- **Documentation**: [GitHub Repository](https://github.com/craigleads/docs)

---

*This document represents the complete technical specification for the Craigslist Lead Generation System v2.0. It should be reviewed quarterly and updated as the system evolves.*

**END OF DOCUMENT**